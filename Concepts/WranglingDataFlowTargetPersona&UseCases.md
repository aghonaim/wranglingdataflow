**Wrangling Data Flow Target Persona & Use Cases**

**Target Persona**: Data Engineer/ “Citizen data integrator”

1.  *Explore and prepare datasets in the lake*

-   With the rise of volume, variety and velocity of data in the data lakes,
    sometimes you need to explore/wrangle/prepare a data set or you are just
    asked to create a new dataset. For example: In the lake, create a dataset
    that “has all customer demographic info for new customers since 2017”.  In
    this case you are not “mapping” to a known target , you are just
    exploring/wrangling/prepping data sets to meet the requirement and then you
    will publish it in the lake.  These are often used for less formal/modelling
    analytics scenarios (i.e. data engineer built a data set for ad hoc
    analysis, data engineer is operationalizing a self-service project built by
    an information worker etc. The prepped datasets can then be used for doing
    any transformations, machine learning operations downstream.

1.  *Code-free agile data preparation*

-   Citizen data integrators spent more than 60% of their time looking for and
    preparing the data. They are looking to do it in a code free manner to
    improve operational productivity. Allowing citizen data integrators to
    enrich, shape, publish the data using known tools like Power Query Online
    (Online version of Power Query in MS excel) in a scalable manner drastically
    improves their productivity. Wrangling Data Flow in Azure Data Factory (ADF)
    enables the familiar Power Query Online mashup editor to allow citizen data
    integrators to fix errors quickly, standardize the data and produce high
    quality data to support business decision makers.

1.  *Fast Data Exploration/Preparation collaboratively \@scale*

-   Multiple data engineers/ citizen data integrators can collaborate to
    explore/prepare the datasets \@cloud scale. Wrangling Data Flow in ADF
    converts the M language generated by Power Query Online to Spark and runs it
    at scale in big data spark environments. It is managed spark as customers
    don’t have to worry about creating, scaling spark clusters. The Azure Data
    Factory service automatically takes care of your scale needs and enables
    data preparation \@cloud scale via spark execution thereby giving you longer
    shelf life for your data preparation solutions.
